{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMdpFqlF7TqyHU5JEWXhfFF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sr1janKundu/Endoscopic_Bleeding_Detection_with_Computer_Vision/blob/main/Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iO57GfBCx0e",
        "outputId": "2181d4fd-8a36-4181-e6e0-7a73b56d3a5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Oct  7 08:17:01 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   59C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbvECLOQTqFl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import imageio\n",
        "#import imageio.v2 as imageio\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Conv2DTranspose\n",
        "from tensorflow.keras.layers import concatenate\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnN1_6wBT68b",
        "outputId": "15d2411b-1cac-4445-a88a-281e3ba00061"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the paths to the training data\n",
        "train_data_path = \"/content/drive/MyDrive/WCEBleedGen/TrainData\"\n",
        "bleeding_path = train_data_path + \"/bleeding\"\n",
        "non_bleeding_path = train_data_path + \"/non-bleeding\"\n",
        "# Define the paths to the images and annotations\n",
        "bleeding_images_path = bleeding_path + \"/Images\"\n",
        "bleeding_annotations_path = bleeding_path + \"/Annotations\"\n",
        "bleeding_bounding_boxes_path = bleeding_path + \"/Bounding boxes/YOLO_TXT\"\n",
        "non_bleeding_images_path = non_bleeding_path + \"/images\"\n",
        "non_bleeding_annotations_path = non_bleeding_path + \"/annotation\""
      ],
      "metadata": {
        "id": "bibnstzlT63k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bleeding\n",
        "## Images\n",
        "image_list_bleeding_orig = os.listdir(bleeding_images_path)\n",
        "image_list_bleeding_orig = list(np.sort(image_list_bleeding_orig))\n",
        "image_list_bleeding = [bleeding_images_path+'/'+i for i in image_list_bleeding_orig]\n",
        "## Masks\n",
        "mask_list_bleeding_orig = os.listdir(bleeding_annotations_path)\n",
        "mask_list_bleeding_orig = list(np.sort(mask_list_bleeding_orig))\n",
        "mask_list_bleeding = [bleeding_annotations_path+'/'+i for i in mask_list_bleeding_orig]\n",
        "\n",
        "# Non Bleeding\n",
        "## Images\n",
        "image_list_non_bleeding_orig = os.listdir(non_bleeding_images_path)\n",
        "image_list_non_bleeding_orig = list(np.sort(image_list_non_bleeding_orig))\n",
        "image_list_non_bleeding = [non_bleeding_images_path+'/'+i for i in image_list_non_bleeding_orig]\n",
        "## Masks\n",
        "mask_list_non_bleeding_orig = os.listdir(non_bleeding_annotations_path)\n",
        "mask_list_non_bleeding_orig = list(np.sort(mask_list_non_bleeding_orig))\n",
        "mask_list_non_bleeding = [bleeding_annotations_path+'/'+i for i in mask_list_non_bleeding_orig]\n"
      ],
      "metadata": {
        "id": "QnnLtl1c_4dU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check some masked and unmasked images"
      ],
      "metadata": {
        "id": "8fk15odSB8GT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N = 23\n",
        "img_t_Bld = imageio.imread(image_list_bleeding[N])\n",
        "mask_t_Bld = imageio.imread(mask_list_bleeding[N])\n",
        "# Convert the black and white mask to a binary mask\n",
        "binary_mask = (mask_t_Bld > 0).astype(np.uint8)  # Assuming the object is represented by non-zero values\n",
        "\n",
        "#mask = np.array([max(mask[i, j]) for i in range(mask.shape[0]) for j in range(mask.shape[1])]).reshape(img.shape[0], img.shape[1])\n",
        "\n",
        "fig, arr = plt.subplots(1, 2, figsize=(14, 10))\n",
        "arr[0].imshow(img_t_Bld)\n",
        "arr[0].set_title('Image')\n",
        "arr[1].imshow(binary_mask, cmap='gray')  # Use cmap='gray' to display it in grayscale\n",
        "arr[1].set_title('Mask')"
      ],
      "metadata": {
        "id": "YoI-NGUoB5yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ImList_b_ds = tf.data.Dataset.list_files(image_list_bleeding, shuffle=False)\n",
        "MskList_b_ds = tf.data.Dataset.list_files(mask_list_bleeding, shuffle=False)\n",
        "\n",
        "for path in zip(ImList_b_ds.take(3), MskList_b_ds.take(3)):\n",
        "    print(path)"
      ],
      "metadata": {
        "id": "Il23sa8ulnAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ImList_nb_ds = tf.data.Dataset.list_files(image_list_non_bleeding, shuffle=False)\n",
        "MskList_nb_ds = tf.data.Dataset.list_files(mask_list_non_bleeding, shuffle=False)\n",
        "\n",
        "for path in zip(ImList_nb_ds.take(3), MskList_nb_ds.take(3)):\n",
        "    print(path)"
      ],
      "metadata": {
        "id": "l11FqHxXlsk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocess"
      ],
      "metadata": {
        "id": "vP6ja_MIVE3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_path(image_path, mask_path):\n",
        "    img = tf.io.read_file(image_path)\n",
        "    img = tf.image.decode_png(img, channels=3)\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "\n",
        "    mask = tf.io.read_file(mask_path)\n",
        "    mask = tf.image.decode_png(mask, channels=3)\n",
        "    mask = tf.math.reduce_max(mask, axis=-1, keepdims=True)\n",
        "    return img, mask\n",
        "\n",
        "def preprocess(image, mask):\n",
        "    input_image = tf.image.resize(image, (96, 128), method='nearest')\n",
        "    input_mask = tf.image.resize(mask, (96, 128), method='nearest')\n",
        "\n",
        "    return input_image, input_mask"
      ],
      "metadata": {
        "id": "0yEepl6xuAN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder (Downsampling Block)"
      ],
      "metadata": {
        "id": "rNSThvR9wcjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(inputs=None, n_filters=32, dropout_prob=0, max_pooling=True):\n",
        "    \"\"\"\n",
        "    Convolutional downsampling block\n",
        "\n",
        "    Arguments:\n",
        "        inputs -- Input tensor\n",
        "        n_filters -- Number of filters for the convolutional layers\n",
        "        dropout_prob -- Dropout probability\n",
        "        max_pooling -- Use MaxPooling2D to reduce the spatial dimensions of the output volume\n",
        "    Returns:\n",
        "        next_layer, skip_connection --  Next layer and skip connection outputs\n",
        "    \"\"\"\n",
        "    conv = Conv2D(n_filters, # Number of filters\n",
        "                  3,   # Kernel size\n",
        "                  activation='relu',\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal')(inputs)\n",
        "    conv = Conv2D(n_filters, # Number of filters\n",
        "                  3,   # Kernel size\n",
        "                  activation='relu',\n",
        "                  padding='same',\n",
        "                  # set 'kernel_initializer' same as above\n",
        "                  kernel_initializer='he_normal')(conv)\n",
        "\n",
        "    # if dropout_prob > 0 add a dropout layer, with the variable dropout_prob as parameter\n",
        "    if dropout_prob > 0:\n",
        "        conv = Dropout(dropout_prob)(conv)\n",
        "\n",
        "    # if max_pooling is True add a MaxPooling2D with 2x2 pool_size\n",
        "    if max_pooling:\n",
        "        next_layer = MaxPooling2D(2,strides=2)(conv)\n",
        "    else:\n",
        "        next_layer = conv\n",
        "\n",
        "    skip_connection = conv\n",
        "\n",
        "    return next_layer, skip_connection"
      ],
      "metadata": {
        "id": "Z9yrwLSMwDqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder (Upsampling Block)"
      ],
      "metadata": {
        "id": "q_XKA65qwi2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def upsampling_block(expansive_input, contractive_input, n_filters=32):\n",
        "    \"\"\"\n",
        "    Convolutional upsampling block\n",
        "\n",
        "    Arguments:\n",
        "        expansive_input -- Input tensor from previous layer\n",
        "        contractive_input -- Input tensor from previous skip layer\n",
        "        n_filters -- Number of filters for the convolutional layers\n",
        "    Returns:\n",
        "        conv -- Tensor output\n",
        "    \"\"\"\n",
        "    up = Conv2DTranspose(\n",
        "                 n_filters,    # number of filters\n",
        "                 3,    # Kernel size\n",
        "                 strides=2,\n",
        "                 padding='same')(expansive_input)\n",
        "\n",
        "    # Merge the previous output and the contractive_input\n",
        "    merge = concatenate([up, contractive_input], axis=3)\n",
        "    conv = Conv2D(n_filters,   # Number of filters\n",
        "                 3,     # Kernel size\n",
        "                 activation='relu',\n",
        "                 padding='same',\n",
        "                 kernel_initializer='he_normal')(merge)\n",
        "    conv = Conv2D(n_filters,  # Number of filters\n",
        "                 3,   # Kernel size\n",
        "                 activation='relu',\n",
        "                 padding='same',\n",
        "                  # set 'kernel_initializer' same as above\n",
        "                 kernel_initializer='he_normal')(conv)\n",
        "\n",
        "    return conv"
      ],
      "metadata": {
        "id": "2mK_85hiwj_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## U-Net Model"
      ],
      "metadata": {
        "id": "GdY80gs8wq2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unet_model(input_size=(96, 128, 3), n_filters=32, n_classes=23):\n",
        "    \"\"\"\n",
        "    Unet model\n",
        "\n",
        "    Arguments:\n",
        "        input_size -- Input shape\n",
        "        n_filters -- Number of filters for the convolutional layers\n",
        "        n_classes -- Number of output classes\n",
        "    Returns:\n",
        "        model -- tf.keras.Model\n",
        "    \"\"\"\n",
        "    inputs = Input(input_size)\n",
        "    # Contracting Path (encoding)\n",
        "    # Add a conv_block with the inputs of the unet_ model and n_filters\n",
        "    cblock1 = conv_block(inputs=inputs, n_filters=n_filters*1)\n",
        "    # Chain the first element of the output of each block to be the input of the next conv_block.\n",
        "    # Double the number of filters at each new step\n",
        "    cblock2 = conv_block(inputs=cblock1[0], n_filters=n_filters*2)\n",
        "    cblock3 = conv_block(inputs=cblock2[0], n_filters=n_filters*4)\n",
        "    cblock4 = conv_block(inputs=cblock3[0], n_filters=n_filters*8,dropout_prob=0.3) # Include a dropout_prob of 0.3 for this layer\n",
        "    # Include a dropout_prob of 0.3 for this layer, and avoid the max_pooling layer\n",
        "    cblock5 = conv_block(inputs=cblock4[0], n_filters=n_filters*16,dropout_prob=0.3, max_pooling=False)\n",
        "\n",
        "    # Expanding Path (decoding)\n",
        "    # Add the first upsampling_block.\n",
        "    # Use the cblock5[0] as expansive_input and cblock4[1] as contractive_input and n_filters * 8\n",
        "    ublock6 = upsampling_block(cblock5[0], cblock4[1], n_filters*8)\n",
        "    # Chain the output of the previous block as expansive_input and the corresponding contractive block output.\n",
        "    # Note that you must use the second element of the contractive block i.e before the maxpooling layer.\n",
        "    # At each step, use half the number of filters of the previous block\n",
        "    ublock7 = upsampling_block(ublock6, cblock3[1], n_filters*4)\n",
        "    ublock8 = upsampling_block(ublock7, cblock2[1], n_filters*2)\n",
        "    ublock9 = upsampling_block(ublock8, cblock1[1], n_filters*1)\n",
        "\n",
        "    conv9 = Conv2D(n_filters,\n",
        "                 3,\n",
        "                 activation='relu',\n",
        "                 padding='same',\n",
        "                 # set 'kernel_initializer' same as above exercises\n",
        "                 kernel_initializer='he_normal')(ublock9)\n",
        "\n",
        "    # Add a Conv2D layer with n_classes filter, kernel size of 1 and a 'same' padding\n",
        "    conv10 = Conv2D(n_classes, 1, padding='same')(conv9)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=conv10)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "H0_lWW0jwsnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Model Dimensions"
      ],
      "metadata": {
        "id": "_Cc2X4aVwzIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_height = 96\n",
        "img_width = 128\n",
        "num_channels = 3\n",
        "\n",
        "unet = unet_model((img_height, img_width, num_channels))"
      ],
      "metadata": {
        "id": "c8cGlN6lw1CZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Summary"
      ],
      "metadata": {
        "id": "GswGyaaSw27W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unet.summary()"
      ],
      "metadata": {
        "id": "jxhLuN0Uw4ye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss Function"
      ],
      "metadata": {
        "id": "Jo0GoCREw6xQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unet.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "3uECL8yDw7xP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Handling"
      ],
      "metadata": {
        "id": "JtPjPUMkw_FO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display(display_list):\n",
        "    plt.figure(figsize=(15, 15))\n",
        "\n",
        "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
        "\n",
        "    for i in range(len(display_list)):\n",
        "        plt.subplot(1, len(display_list), i+1)\n",
        "        plt.title(title[i])\n",
        "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
        "        plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "iXFChfoXxAIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image, mask in image_ds.take(1):\n",
        "    sample_image, sample_mask = image, mask\n",
        "    print(mask.shape)\n",
        "display([sample_image, sample_mask])"
      ],
      "metadata": {
        "id": "1ZzC2vO7xHHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image, mask in processed_image_ds.take(1):\n",
        "    sample_image, sample_mask = image, mask\n",
        "    print(mask.shape)\n",
        "display([sample_image, sample_mask])"
      ],
      "metadata": {
        "id": "JMTGSQQ1xIwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the Model"
      ],
      "metadata": {
        "id": "B3dY2dnSxNUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 5\n",
        "VAL_SUBSPLITS = 5\n",
        "BUFFER_SIZE = 500\n",
        "BATCH_SIZE = 32\n",
        "train_dataset = processed_image_ds.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "print(processed_image_ds.element_spec)\n",
        "model_history = unet.fit(train_dataset, epochs=EPOCHS)"
      ],
      "metadata": {
        "id": "EFgzeQGzxOGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Predicted Masks"
      ],
      "metadata": {
        "id": "n9kL6-x5xRSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_mask(pred_mask):\n",
        "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
        "    pred_mask = pred_mask[..., tf.newaxis]\n",
        "    return pred_mask[0]"
      ],
      "metadata": {
        "id": "6kvxM9wrxT3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot Model Accuracy"
      ],
      "metadata": {
        "id": "ZADIhkaLxV8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(model_history.history[\"accuracy\"])"
      ],
      "metadata": {
        "id": "3H-3TOevxWza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Show Predictions"
      ],
      "metadata": {
        "id": "Sn-NOLO1xZQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_predictions(dataset=None, num=1):\n",
        "    \"\"\"\n",
        "    Displays the first image of each of the num batches\n",
        "    \"\"\"\n",
        "    if dataset:\n",
        "        for image, mask in dataset.take(num):\n",
        "            pred_mask = unet.predict(image)\n",
        "            display([image[0], mask[0], create_mask(pred_mask)])\n",
        "    else:\n",
        "        display([sample_image, sample_mask,\n",
        "             create_mask(unet.predict(sample_image[tf.newaxis, ...]))])"
      ],
      "metadata": {
        "id": "hGIcvAPUxaRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_predictions(train_dataset, 6)"
      ],
      "metadata": {
        "id": "_XzKblIXxceA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}