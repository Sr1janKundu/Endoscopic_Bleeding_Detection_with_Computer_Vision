{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iO57GfBCx0e",
        "outputId": "2181d4fd-8a36-4181-e6e0-7a73b56d3a5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Oct  7 08:17:01 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   59C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbvECLOQTqFl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import imageio\n",
        "#import imageio.v2 as imageio\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Conv2DTranspose\n",
        "from tensorflow.keras.layers import concatenate\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnN1_6wBT68b",
        "outputId": "15d2411b-1cac-4445-a88a-281e3ba00061"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the paths to the training data\n",
        "train_data_path = \"/content/drive/MyDrive/WCEBleedGen/TrainData\"\n",
        "bleeding_path = train_data_path + \"/bleeding\"\n",
        "non_bleeding_path = train_data_path + \"/non-bleeding\"\n",
        "# Define the paths to the images and annotations\n",
        "bleeding_images_path = bleeding_path + \"/Images\"\n",
        "bleeding_annotations_path = bleeding_path + \"/Annotations\"\n",
        "bleeding_bounding_boxes_path = bleeding_path + \"/Bounding boxes/YOLO_TXT\"\n",
        "non_bleeding_images_path = non_bleeding_path + \"/images\"\n",
        "non_bleeding_annotations_path = non_bleeding_path + \"/annotation\""
      ],
      "metadata": {
        "id": "bibnstzlT63k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bleeding\n",
        "## Images\n",
        "image_list_bleeding_orig = os.listdir(bleeding_images_path)\n",
        "image_list_bleeding_orig = list(np.sort(image_list_bleeding_orig))\n",
        "image_list_bleeding = [bleeding_images_path+'/'+i for i in image_list_bleeding_orig]\n",
        "## Masks\n",
        "mask_list_bleeding_orig = os.listdir(bleeding_annotations_path)\n",
        "mask_list_bleeding_orig = list(np.sort(mask_list_bleeding_orig))\n",
        "mask_list_bleeding = [bleeding_annotations_path+'/'+i for i in mask_list_bleeding_orig]\n",
        "\n",
        "# Non Bleeding\n",
        "## Images\n",
        "image_list_non_bleeding_orig = os.listdir(non_bleeding_images_path)\n",
        "image_list_non_bleeding_orig = list(np.sort(image_list_non_bleeding_orig))\n",
        "image_list_non_bleeding = [non_bleeding_images_path+'/'+i for i in image_list_non_bleeding_orig]\n",
        "## Masks\n",
        "mask_list_non_bleeding_orig = os.listdir(non_bleeding_annotations_path)\n",
        "mask_list_non_bleeding_orig = list(np.sort(mask_list_non_bleeding_orig))\n",
        "mask_list_non_bleeding = [bleeding_annotations_path+'/'+i for i in mask_list_non_bleeding_orig]\n"
      ],
      "metadata": {
        "id": "QnnLtl1c_4dU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check some masked and unmasked images"
      ],
      "metadata": {
        "id": "8fk15odSB8GT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N = 23\n",
        "img_t_Bld = imageio.imread(image_list_bleeding[N])\n",
        "mask_t_Bld = imageio.imread(mask_list_bleeding[N])\n",
        "# Convert the black and white mask to a binary mask\n",
        "binary_mask = (mask_t_Bld > 0).astype(np.uint8)  # Assuming the object is represented by non-zero values\n",
        "\n",
        "#mask = np.array([max(mask[i, j]) for i in range(mask.shape[0]) for j in range(mask.shape[1])]).reshape(img.shape[0], img.shape[1])\n",
        "\n",
        "fig, arr = plt.subplots(1, 2, figsize=(14, 10))\n",
        "arr[0].imshow(img_t_Bld)\n",
        "arr[0].set_title('Image')\n",
        "arr[1].imshow(binary_mask, cmap='gray')  # Use cmap='gray' to display it in grayscale\n",
        "arr[1].set_title('Mask')"
      ],
      "metadata": {
        "id": "YoI-NGUoB5yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocess"
      ],
      "metadata": {
        "id": "vP6ja_MIVE3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.constant(image_list_bleeding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEdiUdUtVf7I",
        "outputId": "c0eb7a20-4f89-4069-b132-090956fbdf0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1309,), dtype=string, numpy=\n",
              "array([b'/content/drive/MyDrive/WCEBleedGen/TrainData/bleeding/Images/img- (1).png',\n",
              "       b'/content/drive/MyDrive/WCEBleedGen/TrainData/bleeding/Images/img- (10).png',\n",
              "       b'/content/drive/MyDrive/WCEBleedGen/TrainData/bleeding/Images/img- (100).png',\n",
              "       ...,\n",
              "       b'/content/drive/MyDrive/WCEBleedGen/TrainData/bleeding/Images/img- (997).png',\n",
              "       b'/content/drive/MyDrive/WCEBleedGen/TrainData/bleeding/Images/img- (998).png',\n",
              "       b'/content/drive/MyDrive/WCEBleedGen/TrainData/bleeding/Images/img- (999).png'],\n",
              "      dtype=object)>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_path(image_path, mask_path):\n",
        "    img = tf.io.read_file(image_path)\n",
        "    img = tf.image.decode_png(img, channels=3)\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "\n",
        "    mask = tf.io.read_file(mask_path)\n",
        "    mask = tf.image.decode_png(mask, channels=3)\n",
        "    mask = tf.math.reduce_max(mask, axis=-1, keepdims=True)\n",
        "    return img, mask\n",
        "\n",
        "def preprocess(image, mask):\n",
        "    input_image = tf.image.resize(image, (96, 128), method='nearest')\n",
        "    input_mask = tf.image.resize(mask, (96, 128), method='nearest')\n",
        "\n",
        "    return input_image, input_mask\n",
        "\n",
        "image_ds = dataset.map(process_path)\n",
        "processed_image_ds = image_ds.map(preprocess)"
      ],
      "metadata": {
        "id": "mwaOxvLzIaVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = imageio.imread(image_list[N])\n",
        "mask = imageio.imread(mask_list[N])\n",
        "#mask = np.array([max(mask[i, j]) for i in range(mask.shape[0]) for j in range(mask.shape[1])]).reshape(img.shape[0], img.shape[1])\n",
        "\n",
        "fig, arr = plt.subplots(1, 2, figsize=(14, 10))\n",
        "arr[0].imshow(img)\n",
        "arr[0].set_title('Image')\n",
        "arr[1].imshow(mask[:, :, 0])\n",
        "arr[1].set_title('Segmentation')"
      ],
      "metadata": {
        "id": "ENABTM3KB6qB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "04ILG2rTB694"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list of all the image and annotation paths\n",
        "image_paths = []\n",
        "annotation_paths = []"
      ],
      "metadata": {
        "id": "y6oNH8VNUMVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the bleeding images and annotations to the lists\n",
        "for i in range(1, 1310):\n",
        "    image_path = bleeding_images_path + \"/img- ({})\".format(i) + \".png\"\n",
        "    annotation_path = bleeding_annotations_path + \"/ann- ({})\".format(i) + \".png\"\n",
        "    image_paths.append(image_path)\n",
        "    annotation_paths.append(annotation_path)"
      ],
      "metadata": {
        "id": "yOCF3CkTUN1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the non-bleeding images and annotations to the lists\n",
        "for i in range(1, 1310):\n",
        "    image_path = non_bleeding_images_path + \"/img- ({})\".format(i) + \".png\"\n",
        "    annotation_path = non_bleeding_annotations_path + \"/ann- ({})\".format(i) + \".png\"\n",
        "    image_paths.append(image_path)\n",
        "    annotation_paths.append(annotation_path)"
      ],
      "metadata": {
        "id": "yMV89uidUPFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the images and annotations\n",
        "def preprocess_image(image_path):\n",
        "    \"\"\"Preprocesses an image by converting it to TensorFlow format and resizing it to 224x224.\"\"\"\n",
        "    image = imageio.imread(image_path)\n",
        "    image = image.astype(\"float32\") / 255.0\n",
        "    image = tf.image.resize(image, (224, 224))\n",
        "    return image\n"
      ],
      "metadata": {
        "id": "oDmKyiY5UQ1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_annotation(annotation_path):\n",
        "    \"\"\"Preprocesses an annotation by converting it to a TensorFlow format and resizing it to 224x224.\"\"\"\n",
        "    annotation = imageio.imread(annotation_path)\n",
        "    annotation = annotation.astype(\"float32\")\n",
        "    annotation = tf.expand_dims(annotation, axis=0)\n",
        "    annotation = tf.image.resize(annotation, (224, 224))\n",
        "    return annotation"
      ],
      "metadata": {
        "id": "pfBMjIdyUSq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the images and annotations\n",
        "preprocessed_images = []\n",
        "preprocessed_annotations = []"
      ],
      "metadata": {
        "id": "V_X0ZxXIUUG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_dataset(start_indx, end_indx):\n",
        "    for i in range(start_indx, end_indx):\n",
        "        preprocessed_image = preprocess_image(image_paths[i])\n",
        "        preprocessed_annotation = preprocess_annotation(annotation_paths[i])\n",
        "        return preprocessed_image, preprocessed_annotation"
      ],
      "metadata": {
        "id": "mgyZ97k3UWMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame from the generator\n",
        "data_0 = pd.DataFrame(preprocess_dataset(0, 1309), columns=[\"image\", \"annotation\"])\n",
        "data_1 = pd.DataFrame(preprocess_dataset(1309, 2319), columns=[\"image\", \"annotation\"])"
      ],
      "metadata": {
        "id": "9sIy1_O1UXoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and validation sets\n",
        "train_data, val_data = tf.keras.utils.train_test_split(data, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "RNhNj9nTUZfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the training and validation sets to CSV files\n",
        "train_data.to_csv(\"train_data.csv\", index=False)\n",
        "val_data.to_csv(\"val_data.csv\", index=False)"
      ],
      "metadata": {
        "id": "ldf9Fb_MUbF6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}